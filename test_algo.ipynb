{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "pays_coordinee = {\n",
    "    \"senegal\": {\n",
    "        \"dakar\": (14.6928, -17.4467),\n",
    "        \"thies\": (14.7894, -16.926),\n",
    "        \"saint-louis\": (16.0333, -16.5),\n",
    "        \"kaolack\": (14.151, -16.0726),\n",
    "        \"ziguinchor\": (12.5833, -16.2667),\n",
    "        \"tambacounda\": (13.77, -13.6672),\n",
    "        \"kedougou\": (12.5535, -12.1743),\n",
    "    },\n",
    "    \"mali\": {\n",
    "        \"bamako\": (12.6392, -8.0029),\n",
    "        \"segou\": (13.4317, -6.2157),\n",
    "        \"timbuktu\": (16.7666, -3.0026),\n",
    "        \"mopti\": (14.4843, -4.1827),\n",
    "    },\n",
    "    \"cote_d_ivoire\": {\n",
    "        \"abidjan\": (5.3364, -4.0261),\n",
    "        \"bouake\": (7.6833, -5.0333),\n",
    "        \"yamoussoukro\": (6.8161, -5.2742),\n",
    "        \"san_pedro\": (4.7485, -6.6363),\n",
    "    },\n",
    "    \"guinee\": {\n",
    "        \"conakry\": (9.6412, -13.5784),\n",
    "        \"kankan\": (10.3842, -9.3057),\n",
    "        \"n_zerekore\": (7.7594, -8.8174),\n",
    "        \"labé\": (11.3167, -12.2833),\n",
    "    },\n",
    "    \"nigeria\": {\n",
    "        \"lagos\": (6.5244, 3.3792),\n",
    "        \"abuja\": (9.0579, 7.4951),\n",
    "        \"kano\": (12.0022, 8.5919),\n",
    "    },\n",
    "    \"ghana\": {\n",
    "        \"accra\": (5.6037, -0.187),\n",
    "        \"kumasi\": (6.6666, -1.6163),\n",
    "        \"tamale\": (9.4075, -0.8531),\n",
    "        \"takoradi\": (4.8975, -1.7603),\n",
    "    },\n",
    "    \"burkina faso\": {\n",
    "        \"ouagadougou\": (12.3714, -1.5197),\n",
    "        \"bobo dioulasso\": (11.1786, -4.2979),\n",
    "        \"koudougou\": (12.2542, -2.3625),\n",
    "    },\n",
    "}\n",
    "\n",
    "def __get_url__(lat:str, long:str, start_date:str, end_date:str)->str:\n",
    "    return f\"https://power.larc.nasa.gov/api/temporal/hourly/point?parameters=T2M,RH2M,T2MWET,PRECTOT,WS10M,WD10M,T2MDEW,V10M,PS,QV2M,U10M&community=AG&longitude={long}&latitude={lat}&start={start_date}&end={end_date}&format=json\"\n",
    "\n",
    "\n",
    "def __convert_to_df_optimized__(parameters, city, county):\n",
    "    # Créer directement un dictionnaire avec toutes les dates\n",
    "    dates = list(parameters['T2M'].keys())\n",
    "    n_dates = len(dates)\n",
    "    \n",
    "    data = {\n",
    "        'date': dates,\n",
    "        'ville': [city] * n_dates,\n",
    "        'pays': [county] * n_dates\n",
    "    }\n",
    "    \n",
    "    # Ajouter les paramètres en une seule étape\n",
    "    for param in parameters:\n",
    "        data[param] = [parameters[param].get(date, None) for date in dates]\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def get_data(pays_list, start_date, end_date):\n",
    "    dfs = []\n",
    "    \n",
    "    def fetch_city_data(pays, ville, coordonate):\n",
    "        lat, long = coordonate\n",
    "        url = __get_url__(lat=lat, long=long, start_date=start_date, end_date=end_date)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()[\"properties\"][\"parameter\"]\n",
    "            return __convert_to_df_optimized__(parameters=data, city=ville, county=pays)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur pour {ville}, {pays}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    tasks = []\n",
    "    for pays_loop in pays_list:\n",
    "        if pays_loop.lower() not in [p.lower() for p in pays_coordinee.keys()]:\n",
    "            print(f\"Ce pays n'est pas pris en compte: {pays_loop}\")\n",
    "            continue\n",
    "        \n",
    "        villes = pays_coordinee[pays_loop.lower()]\n",
    "        for ville, coordonate in villes.items():\n",
    "            tasks.append((pays_loop, ville, coordonate))\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(fetch_city_data, pays, ville, coord) for pays, ville, coord in tasks]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                dfs.append(result)\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "\n",
    "date_actuelle = datetime.today()\n",
    "date_delay = datetime.today() - timedelta(days=3)\n",
    "end_date = date_delay.strftime(\"%Y%m%d\")\n",
    "\n",
    "# Date un mois avant\n",
    "start_date_delay = date_delay - timedelta(days=2)\n",
    "start_date = start_date_delay.strftime(\"%Y%m%d\")\n",
    "\n",
    "df = get_data([\"Senegal\",\"mali\",\"cote_d_ivoire\",\"guinee\",\"nigeria\",\"ghana\",\"burkina faso\"],start_date,end_date)\n",
    "df.to_csv(\"Nasa_Power_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Nasa_Power_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, substring, to_date, concat_ws, to_timestamp, lit\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Météo\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_read = pd.read_csv(\"Nasa_Power_data.csv\")\n",
    "\n",
    "df = spark.createDataFrame(pd.DataFrame(df_read))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-----+-----+------+------+----+------+-----+-----+----+-----+-----------+----------+--------------+---------+-------------------+\n",
      "|      date|     ville|   pays|WD10M| RH2M|T2MDEW|T2MWET|U10M|    PS|WS10M| QV2M|V10M|  T2M|PRECTOTCORR|  date_str|date_formatted|heure_str|    heure_formatted|\n",
      "+----------+----------+-------+-----+-----+------+------+----+------+-----+-----+----+-----+-----------+----------+--------------+---------+-------------------+\n",
      "|2025040200|ziguinchor|Senegal|268.3|57.48|  15.7| 20.12|2.77|100.72| 2.77|11.02|0.08|24.54|        0.0|2025040200|    2025-04-02| 00:00:00|2025-04-02 00:00:00|\n",
      "|2025040201|ziguinchor|Senegal|260.0|60.18| 15.77|  19.8|2.22|100.66| 2.25|11.07|0.39|23.84|        0.0|2025040201|    2025-04-02| 01:00:00|2025-04-02 01:00:00|\n",
      "|2025040202|ziguinchor|Senegal|251.2|63.27| 15.97| 19.59| 1.7|100.61|  1.8|11.22|0.58|23.22|        0.0|2025040202|    2025-04-02| 02:00:00|2025-04-02 02:00:00|\n",
      "|2025040203|ziguinchor|Senegal|253.8|67.19| 16.35| 19.49|1.41|100.58| 1.47| 11.5|0.41|22.63|        0.0|2025040203|    2025-04-02| 03:00:00|2025-04-02 03:00:00|\n",
      "|2025040204|ziguinchor|Senegal|269.6|70.37| 16.59| 19.37|1.29| 100.6| 1.29|11.69|0.01|22.14|        0.0|2025040204|    2025-04-02| 04:00:00|2025-04-02 04:00:00|\n",
      "+----------+----------+-------+-----+-----+------+------+----+------+-----+-----+----+-----+-----------+----------+--------------+---------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"date_str\", col(\"date\").cast(\"string\"))\n",
    "df = df.withColumn(\"date_formatted\", to_date(substring(col(\"date_str\"), 1, 8), \"yyyyMMdd\")) \\\n",
    "           .withColumn(\"heure_str\", concat_ws(\":\", substring(col(\"date_str\"), 9, 2), lit(\"00\"), lit(\"00\"))) \\\n",
    "           .withColumn(\"heure_formatted\", concat_ws(\" \", col(\"date_formatted\"), col(\"heure_str\")))\n",
    "# Afficher le résultat\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088, 14)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, substring, to_date, concat_ws, to_timestamp, lit,date_format\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Météo\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_read = pd.read_csv(\"Nasa_Power_data.csv\")\n",
    "print(df_read.shape)\n",
    "\n",
    "def date_hour_colonne(dataframe):\n",
    "    # Créer le DataFrame Spark depuis Pandas\n",
    "    df = spark.createDataFrame(pd.DataFrame(dataframe))\n",
    "    \n",
    "    # Sauvegarder la date brute dans une nouvelle colonne temporaire\n",
    "    df = df.withColumn(\"date_str\", col(\"date\").cast(\"string\"))\n",
    "    \n",
    "    # Extraire la date et l'heure\n",
    "    df = df.withColumn(\"date_formatted\", to_date(substring(col(\"date_str\"), 1, 8), \"yyyyMMdd\")) \\\n",
    "           .withColumn(\"heure_formatted\", concat_ws(\":\", substring(col(\"date_str\"), 9, 2), lit(\"00\"), lit(\"00\"))) \\\n",
    "           #.withColumn(\"heure_formatted\", concat_ws(\" \", col(\"date_formatted\"), col(\"heure_str\"))) \\\n",
    "    \n",
    "    # Obtenir une liste de colonnes sans les colonnes temporaires et les colonnes à remplacer\n",
    "    all_columns = [c for c in df.columns if c not in [\"date_str\", \"heure_str\", \"date\", \"heure\", \"date_formatted\", \"heure_formatted\"]]\n",
    "    \n",
    "    # Sélectionner les colonnes originales plus les nouvelles colonnes transformées\n",
    "    df = df.select(\n",
    "        *all_columns,\n",
    "        col(\"date_formatted\").alias(\"date\"),\n",
    "        col(\"heure_formatted\").alias(\"heure\"),\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def nan_value_manage(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def duplicate_value_manage(df):\n",
    "    return df.dropDuplicates()\n",
    "\n",
    "def transformer_header(df):\n",
    "    # Dictionnaire de correspondance entre les anciennes colonnes et les nouvelles colonnes\n",
    "    header_map = {\n",
    "        'ville': 'ville',\n",
    "        'pays': 'pays',\n",
    "        'T2M': 'temperature_air',\n",
    "        'PS': 'pression',\n",
    "        'WS10M': 'intensite_vent',\n",
    "        'QV2M': 'humidite_specifique',\n",
    "        'T2MDEW': 'temperature_point_rosee',\n",
    "        'U10M': 'composante_est_ouest_vent',\n",
    "        'V10M': 'vitesse_vent',\n",
    "        'RH2M': 'humidite_relative',\n",
    "        'WD10M': 'direction_vent',\n",
    "        'T2MWET': 'temperature_humide',\n",
    "        'PRECTOTCORR': 'precipitations_corrigees',\n",
    "        'date': 'date',\n",
    "        'heure': 'heure'\n",
    "    }\n",
    "    \n",
    "    # Renommer les colonnes du DataFrame\n",
    "    df.rename(columns=header_map, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2088, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = date_hour_colonne(df_read)\n",
    "# nan_value_manage\n",
    "df = nan_value_manage(df)\n",
    "# nan_value_manage\n",
    "#df = duplicate_value_manage(df)\n",
    "\n",
    "df_cleaned = df.toPandas()\n",
    "\n",
    "#Transforme header\n",
    "df_cleaned = transformer_header(df_cleaned)\n",
    "\n",
    "df_cleaned.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>direction_vent</th>\n",
       "      <th>humidite_relative</th>\n",
       "      <th>temperature_point_rosee</th>\n",
       "      <th>temperature_humide</th>\n",
       "      <th>composante_est_ouest_vent</th>\n",
       "      <th>pression</th>\n",
       "      <th>intensite_vent</th>\n",
       "      <th>humidite_specifique</th>\n",
       "      <th>vitesse_vent</th>\n",
       "      <th>temperature_air</th>\n",
       "      <th>precipitations_corrigees</th>\n",
       "      <th>date</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>268.3</td>\n",
       "      <td>57.48</td>\n",
       "      <td>15.70</td>\n",
       "      <td>20.12</td>\n",
       "      <td>2.77</td>\n",
       "      <td>100.72</td>\n",
       "      <td>2.77</td>\n",
       "      <td>11.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>24.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>260.0</td>\n",
       "      <td>60.18</td>\n",
       "      <td>15.77</td>\n",
       "      <td>19.80</td>\n",
       "      <td>2.22</td>\n",
       "      <td>100.66</td>\n",
       "      <td>2.25</td>\n",
       "      <td>11.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>23.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>251.2</td>\n",
       "      <td>63.27</td>\n",
       "      <td>15.97</td>\n",
       "      <td>19.59</td>\n",
       "      <td>1.70</td>\n",
       "      <td>100.61</td>\n",
       "      <td>1.80</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.58</td>\n",
       "      <td>23.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>253.8</td>\n",
       "      <td>67.19</td>\n",
       "      <td>16.35</td>\n",
       "      <td>19.49</td>\n",
       "      <td>1.41</td>\n",
       "      <td>100.58</td>\n",
       "      <td>1.47</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>22.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>269.6</td>\n",
       "      <td>70.37</td>\n",
       "      <td>16.59</td>\n",
       "      <td>19.37</td>\n",
       "      <td>1.29</td>\n",
       "      <td>100.60</td>\n",
       "      <td>1.29</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>22.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ville     pays  direction_vent  humidite_relative  \\\n",
       "0  ziguinchor  Senegal           268.3              57.48   \n",
       "1  ziguinchor  Senegal           260.0              60.18   \n",
       "2  ziguinchor  Senegal           251.2              63.27   \n",
       "3  ziguinchor  Senegal           253.8              67.19   \n",
       "4  ziguinchor  Senegal           269.6              70.37   \n",
       "\n",
       "   temperature_point_rosee  temperature_humide  composante_est_ouest_vent  \\\n",
       "0                    15.70               20.12                       2.77   \n",
       "1                    15.77               19.80                       2.22   \n",
       "2                    15.97               19.59                       1.70   \n",
       "3                    16.35               19.49                       1.41   \n",
       "4                    16.59               19.37                       1.29   \n",
       "\n",
       "   pression  intensite_vent  humidite_specifique  vitesse_vent  \\\n",
       "0    100.72            2.77                11.02          0.08   \n",
       "1    100.66            2.25                11.07          0.39   \n",
       "2    100.61            1.80                11.22          0.58   \n",
       "3    100.58            1.47                11.50          0.41   \n",
       "4    100.60            1.29                11.69          0.01   \n",
       "\n",
       "   temperature_air  precipitations_corrigees        date     heure  \n",
       "0            24.54                       0.0  2025-04-02  00:00:00  \n",
       "1            23.84                       0.0  2025-04-02  01:00:00  \n",
       "2            23.22                       0.0  2025-04-02  02:00:00  \n",
       "3            22.63                       0.0  2025-04-02  03:00:00  \n",
       "4            22.14                       0.0  2025-04-02  04:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>pression</th>\n",
       "      <th>composante_est_ouest_vent</th>\n",
       "      <th>direction_vent</th>\n",
       "      <th>temperature_humide</th>\n",
       "      <th>intensite_vent</th>\n",
       "      <th>temperature_point_rosee</th>\n",
       "      <th>vitesse_vent</th>\n",
       "      <th>temperature_air</th>\n",
       "      <th>humidite_relative</th>\n",
       "      <th>humidite_specifique</th>\n",
       "      <th>precipitations_corrigees</th>\n",
       "      <th>date</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thies</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>101.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.99</td>\n",
       "      <td>5.95</td>\n",
       "      <td>14.81</td>\n",
       "      <td>-5.95</td>\n",
       "      <td>19.18</td>\n",
       "      <td>75.49</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thies</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>100.96</td>\n",
       "      <td>0.36</td>\n",
       "      <td>356.7</td>\n",
       "      <td>17.06</td>\n",
       "      <td>6.25</td>\n",
       "      <td>14.92</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>19.21</td>\n",
       "      <td>75.89</td>\n",
       "      <td>10.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thies</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>100.88</td>\n",
       "      <td>0.55</td>\n",
       "      <td>355.2</td>\n",
       "      <td>17.10</td>\n",
       "      <td>6.53</td>\n",
       "      <td>15.16</td>\n",
       "      <td>-6.51</td>\n",
       "      <td>19.05</td>\n",
       "      <td>77.90</td>\n",
       "      <td>10.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thies</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>100.82</td>\n",
       "      <td>0.43</td>\n",
       "      <td>356.4</td>\n",
       "      <td>17.16</td>\n",
       "      <td>6.78</td>\n",
       "      <td>15.41</td>\n",
       "      <td>-6.77</td>\n",
       "      <td>18.91</td>\n",
       "      <td>79.93</td>\n",
       "      <td>10.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thies</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>100.83</td>\n",
       "      <td>0.23</td>\n",
       "      <td>358.1</td>\n",
       "      <td>17.16</td>\n",
       "      <td>6.84</td>\n",
       "      <td>15.61</td>\n",
       "      <td>-6.84</td>\n",
       "      <td>18.72</td>\n",
       "      <td>81.99</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ville     pays  pression  composante_est_ouest_vent  direction_vent  \\\n",
       "0  thies  Senegal    101.01                      -0.04             0.4   \n",
       "1  thies  Senegal    100.96                       0.36           356.7   \n",
       "2  thies  Senegal    100.88                       0.55           355.2   \n",
       "3  thies  Senegal    100.82                       0.43           356.4   \n",
       "4  thies  Senegal    100.83                       0.23           358.1   \n",
       "\n",
       "   temperature_humide  intensite_vent  temperature_point_rosee  vitesse_vent  \\\n",
       "0               16.99            5.95                    14.81         -5.95   \n",
       "1               17.06            6.25                    14.92         -6.24   \n",
       "2               17.10            6.53                    15.16         -6.51   \n",
       "3               17.16            6.78                    15.41         -6.77   \n",
       "4               17.16            6.84                    15.61         -6.84   \n",
       "\n",
       "   temperature_air  humidite_relative  humidite_specifique  \\\n",
       "0            19.18              75.49                10.40   \n",
       "1            19.21              75.89                10.48   \n",
       "2            19.05              77.90                10.66   \n",
       "3            18.91              79.93                10.85   \n",
       "4            18.72              81.99                11.00   \n",
       "\n",
       "   precipitations_corrigees        date     heure  \n",
       "0                       0.0  2025-03-16  00:00:00  \n",
       "1                       0.0  2025-03-16  01:00:00  \n",
       "2                       0.0  2025-03-16  02:00:00  \n",
       "3                       0.0  2025-03-16  03:00:00  \n",
       "4                       0.0  2025-03-16  04:00:00  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating database 'meteo_db'...\n",
      "Database 'meteo_db' created successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "POSTGRES_USER = \"postgres\"\n",
    "POSTGRES_PASSWORD = \"passer\"\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "DB_NAME = \"meteo_db\"\n",
    "TABLE_NAME = \"meteo_data\"\n",
    "\n",
    "def __create_postgrest_database_if_not_exist__():\n",
    "    try:\n",
    "        # Connexion à la base de données 'postgres' pour vérifier si 'meteo_db' existe\n",
    "        conn = psycopg2.connect(dbname=\"postgres\", user=POSTGRES_USER, password=POSTGRES_PASSWORD, host=POSTGRES_HOST)\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Vérification si la base de données 'meteo_db' existe\n",
    "        cur.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{DB_NAME}';\")\n",
    "        exists = cur.fetchone()\n",
    "        if not exists:\n",
    "            # Si la base de données n'existe pas, on la crée\n",
    "            print(f\"Creating database '{DB_NAME}'...\")\n",
    "            cur.execute(f\"CREATE DATABASE {DB_NAME};\")\n",
    "            print(f\"Database '{DB_NAME}' created successfully\")\n",
    "        else:\n",
    "            print(f\"Database '{DB_NAME}' already exists\")\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database: {e}\")\n",
    "        return False\n",
    "\n",
    "__create_postgrest_database_if_not_exist__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'meteo_cube' already exists\n",
      "Tables created successfully in database 'meteo_cube'\n"
     ]
    }
   ],
   "source": [
    "def __create_cube_if_not_exist__():\n",
    "    db_name = \"meteo_cube\"\n",
    "    try:\n",
    "        # Connexion à la base 'postgres' pour vérifier si la base cible existe\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"postgres\",\n",
    "            user=POSTGRES_USER,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            host=POSTGRES_HOST\n",
    "        )\n",
    "        conn.autocommit = True  # ✅ Placer immédiatement après la connexion\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT 1 FROM pg_database WHERE datname = %s;\", (db_name,))\n",
    "            exists = cur.fetchone()\n",
    "\n",
    "            if not exists:\n",
    "                print(f\"Creating database '{db_name}'...\")\n",
    "                cur.execute(f\"CREATE DATABASE {db_name};\")\n",
    "                print(f\"Database '{db_name}' created successfully\")\n",
    "            else:\n",
    "                print(f\"Database '{db_name}' already exists\")\n",
    "        conn.close()\n",
    "\n",
    "        # Connexion à la base de données cible pour créer les tables\n",
    "        with psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=POSTGRES_USER,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            host=POSTGRES_HOST\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                #cur.execute(f\"CREATE SCHEMA IF NOT EXISTS {db_name};\")\n",
    "\n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS dim_temps (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        date_key INTEGER NOT NULL,\n",
    "                        heure TIME,\n",
    "                        annee INT,\n",
    "                        mois INT,\n",
    "                        nom_mois VARCHAR(15),\n",
    "                        jours INT,\n",
    "                        jours_semaine INT,\n",
    "                        nom_jours VARCHAR (255)\n",
    "                    );\n",
    "                \"\"\")\n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS dim_temperature_humide (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        temperature_humide FLOAT\n",
    "                    );\n",
    "                \"\"\")\n",
    "                \n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS dim_location (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        pays VARCHAR(255),\n",
    "                        ville VARCHAR(255)\n",
    "                    );\n",
    "                \"\"\")\n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS meteo_fait (\n",
    "                    temps_id INT REFERENCES dim_temps(id),\n",
    "                    temperature_humide_id INT REFERENCES dim_temperature_humide(id),\n",
    "                    location_id INT REFERENCES dim_location(id),\n",
    "                    humidite_relative FLOAT,\n",
    "                    temperature_air FLOAT\n",
    "                );\n",
    "                \"\"\")\n",
    "                conn.commit()\n",
    "                print(\"Tables created successfully in database 'meteo_cube'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database or tables: {e}\")\n",
    "        return False\n",
    "    \n",
    "__create_cube_if_not_exist__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'dim_temperature_humide' cleared successfully.\n",
      "Table 'dim_temps' cleared successfully.\n",
      "Table 'dim_location' cleared successfully.\n",
      "Table 'meteo_fait' cleared successfully.\n"
     ]
    }
   ],
   "source": [
    "def __clear_cube__():\n",
    "    db_name = \"meteo_cube\"\n",
    "    try:\n",
    "        # Connexion à la base de données cible\n",
    "        with psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=POSTGRES_USER,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            host=POSTGRES_HOST\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Liste des tables à vider\n",
    "                tables_to_clear = [\n",
    "                    \"dim_temperature_humide\",\n",
    "                    \"dim_temps\",\n",
    "                    \"dim_location\",\n",
    "                    \"meteo_fait\"\n",
    "                ]\n",
    "                \n",
    "                # Exécuter TRUNCATE sur chaque table\n",
    "                for table in tables_to_clear:\n",
    "                    cur.execute(f\"TRUNCATE TABLE {table} RESTART IDENTITY CASCADE;\")\n",
    "                    print(f\"Table '{table}' cleared successfully.\")\n",
    "                \n",
    "                # Commit des modifications\n",
    "                conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing tables: {e}\")\n",
    "        return False\n",
    "    \n",
    "__clear_cube__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>direction_vent</th>\n",
       "      <th>humidite_relative</th>\n",
       "      <th>temperature_point_rosee</th>\n",
       "      <th>temperature_humide</th>\n",
       "      <th>composante_est_ouest_vent</th>\n",
       "      <th>pression</th>\n",
       "      <th>intensite_vent</th>\n",
       "      <th>humidite_specifique</th>\n",
       "      <th>vitesse_vent</th>\n",
       "      <th>temperature_air</th>\n",
       "      <th>precipitations_corrigees</th>\n",
       "      <th>date</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>268.3</td>\n",
       "      <td>57.48</td>\n",
       "      <td>15.70</td>\n",
       "      <td>20.12</td>\n",
       "      <td>2.77</td>\n",
       "      <td>100.72</td>\n",
       "      <td>2.77</td>\n",
       "      <td>11.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>24.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>260.0</td>\n",
       "      <td>60.18</td>\n",
       "      <td>15.77</td>\n",
       "      <td>19.80</td>\n",
       "      <td>2.22</td>\n",
       "      <td>100.66</td>\n",
       "      <td>2.25</td>\n",
       "      <td>11.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>23.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>251.2</td>\n",
       "      <td>63.27</td>\n",
       "      <td>15.97</td>\n",
       "      <td>19.59</td>\n",
       "      <td>1.70</td>\n",
       "      <td>100.61</td>\n",
       "      <td>1.80</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.58</td>\n",
       "      <td>23.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>253.8</td>\n",
       "      <td>67.19</td>\n",
       "      <td>16.35</td>\n",
       "      <td>19.49</td>\n",
       "      <td>1.41</td>\n",
       "      <td>100.58</td>\n",
       "      <td>1.47</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.41</td>\n",
       "      <td>22.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ziguinchor</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>269.6</td>\n",
       "      <td>70.37</td>\n",
       "      <td>16.59</td>\n",
       "      <td>19.37</td>\n",
       "      <td>1.29</td>\n",
       "      <td>100.60</td>\n",
       "      <td>1.29</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>22.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ville     pays  direction_vent  humidite_relative  \\\n",
       "0  ziguinchor  Senegal           268.3              57.48   \n",
       "1  ziguinchor  Senegal           260.0              60.18   \n",
       "2  ziguinchor  Senegal           251.2              63.27   \n",
       "3  ziguinchor  Senegal           253.8              67.19   \n",
       "4  ziguinchor  Senegal           269.6              70.37   \n",
       "\n",
       "   temperature_point_rosee  temperature_humide  composante_est_ouest_vent  \\\n",
       "0                    15.70               20.12                       2.77   \n",
       "1                    15.77               19.80                       2.22   \n",
       "2                    15.97               19.59                       1.70   \n",
       "3                    16.35               19.49                       1.41   \n",
       "4                    16.59               19.37                       1.29   \n",
       "\n",
       "   pression  intensite_vent  humidite_specifique  vitesse_vent  \\\n",
       "0    100.72            2.77                11.02          0.08   \n",
       "1    100.66            2.25                11.07          0.39   \n",
       "2    100.61            1.80                11.22          0.58   \n",
       "3    100.58            1.47                11.50          0.41   \n",
       "4    100.60            1.29                11.69          0.01   \n",
       "\n",
       "   temperature_air  precipitations_corrigees        date     heure  \n",
       "0            24.54                       0.0  2025-04-02  00:00:00  \n",
       "1            23.84                       0.0  2025-04-02  01:00:00  \n",
       "2            23.22                       0.0  2025-04-02  02:00:00  \n",
       "3            22.63                       0.0  2025-04-02  03:00:00  \n",
       "4            22.14                       0.0  2025-04-02  04:00:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ville', 'pays', 'temperature_humide', 'temperature_air',\n",
       "       'intensite_vent', 'direction_vent', 'pression', 'vitesse_vent',\n",
       "       'composante_est_ouest_vent', 'humidite_relative', 'humidite_specifique',\n",
       "       'temperature_point_rosee', 'precipitations_corrigees', 'date', 'heure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ville                         object\n",
       "pays                          object\n",
       "temperature_humide           float64\n",
       "temperature_air              float64\n",
       "intensite_vent               float64\n",
       "direction_vent               float64\n",
       "pression                     float64\n",
       "vitesse_vent                 float64\n",
       "composante_est_ouest_vent    float64\n",
       "humidite_relative            float64\n",
       "humidite_specifique          float64\n",
       "temperature_point_rosee      float64\n",
       "precipitations_corrigees     float64\n",
       "date                          object\n",
       "heure                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14616, 15)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 15 columns\n",
      "DataFrame columns: ['ville', 'pays', 'direction_vent', 'humidite_relative', 'temperature_point_rosee', 'temperature_humide', 'composante_est_ouest_vent', 'pression', 'intensite_vent', 'humidite_specifique', 'vitesse_vent', 'temperature_air', 'precipitations_corrigees', 'date', 'heure']\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted final batch of 88 rows\n",
      "Data insertion completed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def insert_postgres_data(dataframe, batch_size=200):\n",
    "     # Connexion à PostgreSQL\n",
    "    conn = psycopg2.connect(dbname=DB_NAME, user=POSTGRES_USER, password=POSTGRES_PASSWORD, host=POSTGRES_HOST)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Créer la table si elle n'existe pas (en respectant le bon ordre)\n",
    "    cur.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            ville VARCHAR(255),\n",
    "            pays VARCHAR(255),\n",
    "            temperature_air FLOAT,\n",
    "            pression FLOAT,\n",
    "            intensite_vent FLOAT,\n",
    "            humidite_specifique FLOAT,\n",
    "            temperature_point_rosee FLOAT,\n",
    "            composante_est_ouest_vent FLOAT,\n",
    "            vitesse_vent FLOAT,\n",
    "            humidite_relative FLOAT,\n",
    "            direction_vent FLOAT,\n",
    "            temperature_humide FLOAT,\n",
    "            precipitations_corrigees FLOAT,\n",
    "            date DATE,\n",
    "            heure VARCHAR(255)\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    \n",
    "    # Vérifier le nombre de colonnes dans le DataFrame\n",
    "    column_count = len(dataframe.columns)\n",
    "    print(f\"DataFrame has {column_count} columns\")\n",
    "    print(f\"DataFrame columns: {dataframe.columns.tolist()}\")\n",
    "    \n",
    "    # Liste des colonnes attendues dans le bon ordre\n",
    "    expected_columns = [\n",
    "        'ville', 'pays', 'temperature_air', 'pression', 'intensite_vent', \n",
    "        'humidite_specifique', 'temperature_point_rosee', 'composante_est_ouest_vent',\n",
    "        'vitesse_vent', 'humidite_relative', 'direction_vent', \n",
    "        'temperature_humide', 'precipitations_corrigees', 'date', 'heure'\n",
    "    ]\n",
    "    \n",
    "    # Ajuster le DataFrame\n",
    "    dataframe = dataframe[expected_columns]\n",
    "        \n",
    "    # Préparer les données pour l'insertion\n",
    "    batch = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        row_tuple = tuple(row.values)\n",
    "        if len(row_tuple) != 15:\n",
    "            print(f\"Warning: Row has {len(row_tuple)} values, expected 15\")\n",
    "            continue\n",
    "        batch.append(row_tuple)\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            try:\n",
    "                query = f\"\"\"\n",
    "                    INSERT INTO {TABLE_NAME} \n",
    "                    (\n",
    "                        ville, pays, temperature_air, pression, intensite_vent, \n",
    "                        humidite_specifique, temperature_point_rosee, composante_est_ouest_vent,\n",
    "                        vitesse_vent, humidite_relative, direction_vent, \n",
    "                        temperature_humide, precipitations_corrigees, date, heure\n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                cur.executemany(query, batch)\n",
    "                conn.commit()\n",
    "                print(f\"Inserted batch of {len(batch)} rows\")\n",
    "                batch = []\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting batch: {e}\")\n",
    "                if batch:\n",
    "                    print(f\"First row in batch: {batch[0]}\")\n",
    "                conn.rollback()\n",
    "    \n",
    "    # Insérer le dernier batch\n",
    "    if batch:\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "                INSERT INTO {TABLE_NAME} \n",
    "                (\n",
    "                    ville, pays, temperature_air, pression, intensite_vent, \n",
    "                    humidite_specifique, temperature_point_rosee, composante_est_ouest_vent,\n",
    "                    vitesse_vent, humidite_relative, direction_vent, \n",
    "                    temperature_humide, precipitations_corrigees, date, heure\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.executemany(query, batch)\n",
    "            conn.commit()\n",
    "            print(f\"Inserted final batch of {len(batch)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting final batch: {e}\")\n",
    "            if batch:\n",
    "                print(f\"First row in batch: {batch[0]}\")\n",
    "            conn.rollback()\n",
    "    \n",
    "    print(\"Data insertion completed\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# Exemple d'appel à la fonction\n",
    "insert_postgres_data(df_cleaned, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'dim_location' cleared successfully.\n",
      "Table 'dim_name' cleared successfully.\n",
      "Table 'dim_company' cleared successfully.\n",
      "Table 'dim_date_time' cleared successfully.\n",
      "Table 'dim_fact' cleared successfully.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "def __clear_cube__():\n",
    "    try:\n",
    "        # Connexion à la base de données cible\n",
    "        with psycopg2.connect(\n",
    "            dbname=\"generete_currency_data_fact\",\n",
    "            user=\"postgres\",\n",
    "            password=\"passer\",\n",
    "            host=\"localhost\"\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Liste des tables à vider\n",
    "                tables_to_clear = [\n",
    "                    \"dim_location\",\n",
    "                    \"dim_name\",\n",
    "                    \"dim_company\",\n",
    "                    \"dim_date_time\",\n",
    "                    \"dim_fact\"\n",
    "                ]\n",
    "                \n",
    "                # Exécuter TRUNCATE sur chaque table\n",
    "                for table in tables_to_clear:\n",
    "                    cur.execute(f\"TRUNCATE TABLE {table} RESTART IDENTITY CASCADE;\")\n",
    "                    print(f\"Table '{table}' cleared successfully.\")\n",
    "                \n",
    "                # Commit des modifications\n",
    "                conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing tables: {e}\")\n",
    "        return False\n",
    "    \n",
    "__clear_cube__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
