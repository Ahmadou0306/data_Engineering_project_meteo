{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur pour labé, guinee: 'properties'\n",
      "Erreur pour tamale, ghana: 'properties'\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "pays_coordinee = {\n",
    "    \"senegal\": {\n",
    "        \"dakar\": (14.6928, -17.4467),\n",
    "        \"thies\": (14.7894, -16.926),\n",
    "        \"saint-louis\": (16.0333, -16.5),\n",
    "        \"kaolack\": (14.151, -16.0726),\n",
    "        \"ziguinchor\": (12.5833, -16.2667),\n",
    "        \"tambacounda\": (13.77, -13.6672),\n",
    "        \"kedougou\": (12.5535, -12.1743),\n",
    "    },\n",
    "    \"mali\": {\n",
    "        \"bamako\": (12.6392, -8.0029),\n",
    "        \"segou\": (13.4317, -6.2157),\n",
    "        \"timbuktu\": (16.7666, -3.0026),\n",
    "        \"mopti\": (14.4843, -4.1827),\n",
    "    },\n",
    "    \"cote_d_ivoire\": {\n",
    "        \"abidjan\": (5.3364, -4.0261),\n",
    "        \"bouake\": (7.6833, -5.0333),\n",
    "        \"yamoussoukro\": (6.8161, -5.2742),\n",
    "        \"san_pedro\": (4.7485, -6.6363),\n",
    "    },\n",
    "    \"guinee\": {\n",
    "        \"conakry\": (9.6412, -13.5784),\n",
    "        \"kankan\": (10.3842, -9.3057),\n",
    "        \"n_zerekore\": (7.7594, -8.8174),\n",
    "        \"labé\": (11.3167, -12.2833),\n",
    "    },\n",
    "    \"nigeria\": {\n",
    "        \"lagos\": (6.5244, 3.3792),\n",
    "        \"abuja\": (9.0579, 7.4951),\n",
    "        \"kano\": (12.0022, 8.5919),\n",
    "    },\n",
    "    \"ghana\": {\n",
    "        \"accra\": (5.6037, -0.187),\n",
    "        \"kumasi\": (6.6666, -1.6163),\n",
    "        \"tamale\": (9.4075, -0.8531),\n",
    "        \"takoradi\": (4.8975, -1.7603),\n",
    "    },\n",
    "    \"burkina faso\": {\n",
    "        \"ouagadougou\": (12.3714, -1.5197),\n",
    "        \"bobo dioulasso\": (11.1786, -4.2979),\n",
    "        \"koudougou\": (12.2542, -2.3625),\n",
    "    },\n",
    "}\n",
    "\n",
    "def __get_url__(lat:str, long:str, start_date:str, end_date:str)->str:\n",
    "    return f\"https://power.larc.nasa.gov/api/temporal/hourly/point?parameters=T2M,RH2M,T2MWET,PRECTOT,WS10M,WD10M,T2MDEW,V10M,PS,QV2M,U10M&community=AG&longitude={long}&latitude={lat}&start={start_date}&end={end_date}&format=json\"\n",
    "\n",
    "\n",
    "def __convert_to_df_optimized__(parameters, city, county):\n",
    "    # Créer directement un dictionnaire avec toutes les dates\n",
    "    dates = list(parameters['T2M'].keys())\n",
    "    n_dates = len(dates)\n",
    "    \n",
    "    data = {\n",
    "        'date': dates,\n",
    "        'ville': [city] * n_dates,\n",
    "        'pays': [county] * n_dates\n",
    "    }\n",
    "    \n",
    "    # Ajouter les paramètres en une seule étape\n",
    "    for param in parameters:\n",
    "        data[param] = [parameters[param].get(date, None) for date in dates]\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def get_data(pays_list, start_date, end_date):\n",
    "    dfs = []\n",
    "    \n",
    "    def fetch_city_data(pays, ville, coordonate):\n",
    "        lat, long = coordonate\n",
    "        url = __get_url__(lat=lat, long=long, start_date=start_date, end_date=end_date)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()[\"properties\"][\"parameter\"]\n",
    "            return __convert_to_df_optimized__(parameters=data, city=ville, county=pays)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur pour {ville}, {pays}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    tasks = []\n",
    "    for pays_loop in pays_list:\n",
    "        if pays_loop.lower() not in [p.lower() for p in pays_coordinee.keys()]:\n",
    "            print(f\"Ce pays n'est pas pris en compte: {pays_loop}\")\n",
    "            continue\n",
    "        \n",
    "        villes = pays_coordinee[pays_loop.lower()]\n",
    "        for ville, coordonate in villes.items():\n",
    "            tasks.append((pays_loop, ville, coordonate))\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(fetch_city_data, pays, ville, coord) for pays, ville, coord in tasks]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                dfs.append(result)\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "\n",
    "date_actuelle = datetime.today()\n",
    "date_delay = datetime.today() - timedelta(days=8)\n",
    "end_date = date_delay.strftime(\"%Y%m%d\")\n",
    "\n",
    "# Date un mois avant\n",
    "start_date_delay = date_delay - timedelta(days=75)\n",
    "start_date = start_date_delay.strftime(\"%Y%m%d\")\n",
    "\n",
    "df = get_data([\"Senegal\",\"mali\",\"cote_d_ivoire\",\"guinee\",\"nigeria\",\"ghana\",\"burkina faso\"],start_date,end_date)\n",
    "df.to_csv(\"Nasa_Power_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>WS10M</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>U10M</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>PS</th>\n",
       "      <th>T2M</th>\n",
       "      <th>WD10M</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>V10M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025011500</td>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.18</td>\n",
       "      <td>6.16</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>12.01</td>\n",
       "      <td>101.01</td>\n",
       "      <td>17.46</td>\n",
       "      <td>20.3</td>\n",
       "      <td>49.94</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>6.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025011501</td>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5.69</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>11.21</td>\n",
       "      <td>100.95</td>\n",
       "      <td>16.92</td>\n",
       "      <td>23.9</td>\n",
       "      <td>47.72</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025011502</td>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.28</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>10.43</td>\n",
       "      <td>100.92</td>\n",
       "      <td>16.36</td>\n",
       "      <td>26.1</td>\n",
       "      <td>45.88</td>\n",
       "      <td>-3.72</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025011503</td>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5.07</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>9.85</td>\n",
       "      <td>100.91</td>\n",
       "      <td>15.74</td>\n",
       "      <td>26.8</td>\n",
       "      <td>45.84</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025011504</td>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.03</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>9.48</td>\n",
       "      <td>100.95</td>\n",
       "      <td>15.11</td>\n",
       "      <td>25.5</td>\n",
       "      <td>47.37</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        ville     pays  WS10M  QV2M  U10M  T2MWET      PS    T2M  \\\n",
       "0  2025011500  saint-louis  Senegal   4.18  6.16 -1.45   12.01  101.01  17.46   \n",
       "1  2025011501  saint-louis  Senegal   4.15  5.69 -1.68   11.21  100.95  16.92   \n",
       "2  2025011502  saint-louis  Senegal   4.14  5.28 -1.82   10.43  100.92  16.36   \n",
       "3  2025011503  saint-louis  Senegal   4.13  5.07 -1.86    9.85  100.91  15.74   \n",
       "4  2025011504  saint-louis  Senegal   4.07  5.03 -1.75    9.48  100.95  15.11   \n",
       "\n",
       "   WD10M   RH2M  V10M  T2MDEW  PRECTOTCORR  \n",
       "0   20.3  49.94 -3.92    6.56          0.0  \n",
       "1   23.9  47.72 -3.80    5.50          0.0  \n",
       "2   26.1  45.88 -3.72    4.50          0.0  \n",
       "3   26.8  45.84 -3.69    3.95          0.0  \n",
       "4   25.5  47.37 -3.67    3.85          0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Nasa_Power_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, substring, to_date, concat_ws, to_timestamp, lit\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Météo\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_read = pd.read_csv(\"Nasa_Power_data.csv\")\n",
    "\n",
    "df = spark.createDataFrame(pd.DataFrame(df_read))\n",
    "\n",
    "df = df.withColumn(\"date_str\", col(\"date\").cast(\"string\"))\n",
    "df = df.withColumn(\"date_formatted\", to_date(substring(col(\"date_str\"), 1, 8), \"yyyyMMdd\")) \\\n",
    "           .withColumn(\"heure_str\", concat_ws(\":\", substring(col(\"date_str\"), 9, 2), lit(\"00\"), lit(\"00\"))) \\\n",
    "           .withColumn(\"heure_formatted\", concat_ws(\" \", col(\"date_formatted\"), col(\"heure_str\")))\n",
    "# Afficher le résultat\n",
    "df.show(5)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49248, 14)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, substring, to_date, concat_ws, to_timestamp, lit,date_format\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Météo\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_read = pd.read_csv(\"Nasa_Power_data.csv\")\n",
    "print(df_read.shape)\n",
    "\n",
    "def date_hour_colonne(dataframe):\n",
    "    # Créer le DataFrame Spark depuis Pandas\n",
    "    df = spark.createDataFrame(pd.DataFrame(dataframe))\n",
    "    \n",
    "    # Sauvegarder la date brute dans une nouvelle colonne temporaire\n",
    "    df = df.withColumn(\"date_str\", col(\"date\").cast(\"string\"))\n",
    "    \n",
    "    # Extraire la date et l'heure\n",
    "    df = df.withColumn(\"date_formatted\", to_date(substring(col(\"date_str\"), 1, 8), \"yyyyMMdd\")) \\\n",
    "           .withColumn(\"heure_formatted\", concat_ws(\":\", substring(col(\"date_str\"), 9, 2), lit(\"00\"), lit(\"00\"))) \\\n",
    "           #.withColumn(\"heure_formatted\", concat_ws(\" \", col(\"date_formatted\"), col(\"heure_str\"))) \\\n",
    "    \n",
    "    # Obtenir une liste de colonnes sans les colonnes temporaires et les colonnes à remplacer\n",
    "    all_columns = [c for c in df.columns if c not in [\"date_str\", \"heure_str\", \"date\", \"heure\", \"date_formatted\", \"heure_formatted\"]]\n",
    "    \n",
    "    # Sélectionner les colonnes originales plus les nouvelles colonnes transformées\n",
    "    df = df.select(\n",
    "        *all_columns,\n",
    "        col(\"date_formatted\").alias(\"date\"),\n",
    "        col(\"heure_formatted\").alias(\"heure\"),\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def nan_value_manage(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def duplicate_value_manage(df):\n",
    "    return df.dropDuplicates()\n",
    "\n",
    "def remove_invalid_rows(df):\n",
    "    # Supprimer les lignes où T2MWET < -30 ou RH2M < -30\n",
    "    df = df.filter((col(\"T2MWET\") >= -30) & (col(\"RH2M\") >= -30))\n",
    "    return df\n",
    "\n",
    "def transformer_header(df):\n",
    "    # Dictionnaire de correspondance entre les anciennes colonnes et les nouvelles colonnes\n",
    "    header_map = {\n",
    "        'ville': 'ville',\n",
    "        'pays': 'pays',\n",
    "        'T2M': 'temperature_air',\n",
    "        'PS': 'pression',\n",
    "        'WS10M': 'intensite_vent',\n",
    "        'QV2M': 'humidite_specifique',\n",
    "        'T2MDEW': 'temperature_point_rosee',\n",
    "        'U10M': 'composante_est_ouest_vent',\n",
    "        'V10M': 'vitesse_vent',\n",
    "        'RH2M': 'humidite_relative',\n",
    "        'WD10M': 'direction_vent',\n",
    "        'T2MWET': 'temperature_humide',\n",
    "        'PRECTOTCORR': 'precipitations_corrigees',\n",
    "        'date': 'date',\n",
    "        'heure': 'heure'\n",
    "    }\n",
    "    \n",
    "    # Renommer les colonnes du DataFrame\n",
    "    df.rename(columns=header_map, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49248, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = date_hour_colonne(df_read)\n",
    "# nan_value_manage\n",
    "df = nan_value_manage(df)\n",
    "# nan_value_manage\n",
    "df = duplicate_value_manage(df)\n",
    "df_cleaned = remove_invalid_rows(df)\n",
    "\n",
    "df_cleaned = df.toPandas()\n",
    "\n",
    "#Transforme header\n",
    "df_cleaned = transformer_header(df_cleaned)\n",
    "\n",
    "\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>intensite_vent</th>\n",
       "      <th>humidite_specifique</th>\n",
       "      <th>composante_est_ouest_vent</th>\n",
       "      <th>temperature_humide</th>\n",
       "      <th>pression</th>\n",
       "      <th>temperature_air</th>\n",
       "      <th>direction_vent</th>\n",
       "      <th>humidite_relative</th>\n",
       "      <th>vitesse_vent</th>\n",
       "      <th>temperature_point_rosee</th>\n",
       "      <th>precipitations_corrigees</th>\n",
       "      <th>date</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.03</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>9.48</td>\n",
       "      <td>100.95</td>\n",
       "      <td>15.11</td>\n",
       "      <td>25.5</td>\n",
       "      <td>47.37</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.63</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>10.74</td>\n",
       "      <td>101.19</td>\n",
       "      <td>18.74</td>\n",
       "      <td>33.2</td>\n",
       "      <td>34.73</td>\n",
       "      <td>-4.58</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>5.08</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.96</td>\n",
       "      <td>101.12</td>\n",
       "      <td>19.79</td>\n",
       "      <td>349.9</td>\n",
       "      <td>54.65</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.80</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.48</td>\n",
       "      <td>15.23</td>\n",
       "      <td>101.11</td>\n",
       "      <td>18.81</td>\n",
       "      <td>354.3</td>\n",
       "      <td>64.02</td>\n",
       "      <td>-4.78</td>\n",
       "      <td>11.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>4.01</td>\n",
       "      <td>9.52</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>14.01</td>\n",
       "      <td>101.09</td>\n",
       "      <td>15.56</td>\n",
       "      <td>17.4</td>\n",
       "      <td>86.99</td>\n",
       "      <td>-3.83</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-16</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ville     pays  intensite_vent  humidite_specifique  \\\n",
       "0  saint-louis  Senegal            4.07                 5.03   \n",
       "1  saint-louis  Senegal            5.48                 4.63   \n",
       "2  saint-louis  Senegal            5.08                 7.80   \n",
       "3  saint-louis  Senegal            4.80                 8.60   \n",
       "4  saint-louis  Senegal            4.01                 9.52   \n",
       "\n",
       "   composante_est_ouest_vent  temperature_humide  pression  temperature_air  \\\n",
       "0                      -1.75                9.48    100.95            15.11   \n",
       "1                      -3.00               10.74    101.19            18.74   \n",
       "2                       0.89               14.96    101.12            19.79   \n",
       "3                       0.48               15.23    101.11            18.81   \n",
       "4                      -1.20               14.01    101.09            15.56   \n",
       "\n",
       "   direction_vent  humidite_relative  vitesse_vent  temperature_point_rosee  \\\n",
       "0            25.5              47.37         -3.67                     3.85   \n",
       "1            33.2              34.73         -4.58                     2.74   \n",
       "2           349.9              54.65         -5.00                    10.13   \n",
       "3           354.3              64.02         -4.78                    11.64   \n",
       "4            17.4              86.99         -3.83                    12.46   \n",
       "\n",
       "   precipitations_corrigees        date     heure  \n",
       "0                       0.0  2025-01-15  04:00:00  \n",
       "1                       0.0  2025-01-15  08:00:00  \n",
       "2                       0.0  2025-01-15  21:00:00  \n",
       "3                       0.0  2025-01-15  22:00:00  \n",
       "4                       0.0  2025-01-16  04:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'meteo_db' already exists\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "POSTGRES_USER = \"postgres\"\n",
    "POSTGRES_PASSWORD = \"passer\"\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "DB_NAME = \"meteo_db\"\n",
    "TABLE_NAME = \"meteo_data\"\n",
    "\n",
    "def __create_postgrest_database_if_not_exist__():\n",
    "    try:\n",
    "        # Connexion à la base de données 'postgres' pour vérifier si 'meteo_db' existe\n",
    "        conn = psycopg2.connect(dbname=\"postgres\", user=POSTGRES_USER, password=POSTGRES_PASSWORD, host=POSTGRES_HOST)\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Vérification si la base de données 'meteo_db' existe\n",
    "        cur.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{DB_NAME}';\")\n",
    "        exists = cur.fetchone()\n",
    "        if not exists:\n",
    "            # Si la base de données n'existe pas, on la crée\n",
    "            print(f\"Creating database '{DB_NAME}'...\")\n",
    "            cur.execute(f\"CREATE DATABASE {DB_NAME};\")\n",
    "            print(f\"Database '{DB_NAME}' created successfully\")\n",
    "        else:\n",
    "            print(f\"Database '{DB_NAME}' already exists\")\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database: {e}\")\n",
    "        return False\n",
    "\n",
    "__create_postgrest_database_if_not_exist__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'meteo_cube' already exists\n",
      "Tables created successfully in database 'meteo_cube'\n"
     ]
    }
   ],
   "source": [
    "def __create_cube_if_not_exist__():\n",
    "    db_name = \"meteo_cube\"\n",
    "    try:\n",
    "        # Connexion à la base 'postgres' pour vérifier si la base cible existe\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"postgres\",\n",
    "            user=POSTGRES_USER,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            host=POSTGRES_HOST\n",
    "        )\n",
    "        conn.autocommit = True  # ✅ Placer immédiatement après la connexion\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT 1 FROM pg_database WHERE datname = %s;\", (db_name,))\n",
    "            exists = cur.fetchone()\n",
    "\n",
    "            if not exists:\n",
    "                print(f\"Creating database '{db_name}'...\")\n",
    "                cur.execute(f\"CREATE DATABASE {db_name};\")\n",
    "                print(f\"Database '{db_name}' created successfully\")\n",
    "            else:\n",
    "                print(f\"Database '{db_name}' already exists\")\n",
    "        conn.close()\n",
    "\n",
    "        # Connexion à la base de données cible pour créer les tables\n",
    "        with psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=POSTGRES_USER,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            host=POSTGRES_HOST\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                #cur.execute(f\"CREATE SCHEMA IF NOT EXISTS {db_name};\")\n",
    "\n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS dim_temps (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        date_key INTEGER NOT NULL,\n",
    "                        heure TIME,\n",
    "                        annee INT,\n",
    "                        mois INT,\n",
    "                        nom_mois VARCHAR(15),\n",
    "                        jours INT,\n",
    "                        jours_semaine INT,\n",
    "                        nom_jours VARCHAR (255)\n",
    "                    );\n",
    "                \"\"\")\n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS dim_temperature_humide (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        temperature_humide FLOAT\n",
    "                    );\n",
    "                \"\"\")\n",
    "                \n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS dim_location (\n",
    "                        id SERIAL PRIMARY KEY,\n",
    "                        pays VARCHAR(255),\n",
    "                        ville VARCHAR(255)\n",
    "                    );\n",
    "                \"\"\")\n",
    "                cur.execute(f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS meteo_fait (\n",
    "                    temps_id INT REFERENCES dim_temps(id),\n",
    "                    temperature_humide_id INT REFERENCES dim_temperature_humide(id),\n",
    "                    location_id INT REFERENCES dim_location(id),\n",
    "                    humidite_relative FLOAT,\n",
    "                    temperature_air FLOAT\n",
    "                );\n",
    "                \"\"\")\n",
    "                conn.commit()\n",
    "                print(\"Tables created successfully in database 'meteo_cube'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database or tables: {e}\")\n",
    "        return False\n",
    "    \n",
    "__create_cube_if_not_exist__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'dim_temperature_humide' cleared successfully.\n",
      "Table 'dim_temps' cleared successfully.\n",
      "Table 'dim_location' cleared successfully.\n",
      "Table 'meteo_fait' cleared successfully.\n"
     ]
    }
   ],
   "source": [
    "def __clear_cube__():\n",
    "    db_name = \"meteo_cube\"\n",
    "    try:\n",
    "        # Connexion à la base de données cible\n",
    "        with psycopg2.connect(\n",
    "            dbname=db_name,\n",
    "            user=POSTGRES_USER,\n",
    "            password=POSTGRES_PASSWORD,\n",
    "            host=POSTGRES_HOST\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Liste des tables à vider\n",
    "                tables_to_clear = [\n",
    "                    \"dim_temperature_humide\",\n",
    "                    \"dim_temps\",\n",
    "                    \"dim_location\",\n",
    "                    \"meteo_fait\"\n",
    "                ]\n",
    "                \n",
    "                # Exécuter TRUNCATE sur chaque table\n",
    "                for table in tables_to_clear:\n",
    "                    cur.execute(f\"TRUNCATE TABLE {table} RESTART IDENTITY CASCADE;\")\n",
    "                    print(f\"Table '{table}' cleared successfully.\")\n",
    "                \n",
    "                # Commit des modifications\n",
    "                conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing tables: {e}\")\n",
    "        return False\n",
    "    \n",
    "__clear_cube__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>temperature_humide</th>\n",
       "      <th>temperature_air</th>\n",
       "      <th>humidite_specifique</th>\n",
       "      <th>vitesse_vent</th>\n",
       "      <th>intensite_vent</th>\n",
       "      <th>humidite_relative</th>\n",
       "      <th>direction_vent</th>\n",
       "      <th>temperature_point_rosee</th>\n",
       "      <th>composante_est_ouest_vent</th>\n",
       "      <th>pression</th>\n",
       "      <th>precipitations_corrigees</th>\n",
       "      <th>date</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kedougou</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>9.38</td>\n",
       "      <td>20.57</td>\n",
       "      <td>3.38</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>4.17</td>\n",
       "      <td>22.04</td>\n",
       "      <td>56.7</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>98.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kedougou</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>8.85</td>\n",
       "      <td>19.44</td>\n",
       "      <td>3.40</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>3.77</td>\n",
       "      <td>23.77</td>\n",
       "      <td>60.7</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>98.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kedougou</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>8.39</td>\n",
       "      <td>18.40</td>\n",
       "      <td>3.43</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>3.47</td>\n",
       "      <td>25.58</td>\n",
       "      <td>65.3</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>98.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kedougou</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>8.01</td>\n",
       "      <td>17.36</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>2.94</td>\n",
       "      <td>27.95</td>\n",
       "      <td>74.4</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>98.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kedougou</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>7.75</td>\n",
       "      <td>16.34</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.44</td>\n",
       "      <td>30.93</td>\n",
       "      <td>90.2</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>98.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ville     pays  temperature_humide  temperature_air  \\\n",
       "0  kedougou  Senegal                9.38            20.57   \n",
       "1  kedougou  Senegal                8.85            19.44   \n",
       "2  kedougou  Senegal                8.39            18.40   \n",
       "3  kedougou  Senegal                8.01            17.36   \n",
       "4  kedougou  Senegal                7.75            16.34   \n",
       "\n",
       "   humidite_specifique  vitesse_vent  intensite_vent  humidite_relative  \\\n",
       "0                 3.38         -2.29            4.17              22.04   \n",
       "1                 3.40         -1.85            3.77              23.77   \n",
       "2                 3.43         -1.45            3.47              25.58   \n",
       "3                 3.51         -0.79            2.94              27.95   \n",
       "4                 3.64          0.01            2.44              30.93   \n",
       "\n",
       "   direction_vent  temperature_point_rosee  composante_est_ouest_vent  \\\n",
       "0            56.7                    -1.82                      -3.49   \n",
       "1            60.7                    -1.75                      -3.29   \n",
       "2            65.3                    -1.63                      -3.15   \n",
       "3            74.4                    -1.35                      -2.83   \n",
       "4            90.2                    -0.84                      -2.44   \n",
       "\n",
       "   pression  precipitations_corrigees        date     heure  \n",
       "0     98.50                       0.0  2025-02-01  00:00:00  \n",
       "1     98.46                       0.0  2025-02-01  01:00:00  \n",
       "2     98.43                       0.0  2025-02-01  02:00:00  \n",
       "3     98.43                       0.0  2025-02-01  03:00:00  \n",
       "4     98.46                       0.0  2025-02-01  04:00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ville', 'pays', 'temperature_humide', 'temperature_air',\n",
       "       'intensite_vent', 'direction_vent', 'pression', 'vitesse_vent',\n",
       "       'composante_est_ouest_vent', 'humidite_relative', 'humidite_specifique',\n",
       "       'temperature_point_rosee', 'precipitations_corrigees', 'date', 'heure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ville                         object\n",
       "pays                          object\n",
       "temperature_humide           float64\n",
       "temperature_air              float64\n",
       "intensite_vent               float64\n",
       "direction_vent               float64\n",
       "pression                     float64\n",
       "vitesse_vent                 float64\n",
       "composante_est_ouest_vent    float64\n",
       "humidite_relative            float64\n",
       "humidite_specifique          float64\n",
       "temperature_point_rosee      float64\n",
       "precipitations_corrigees     float64\n",
       "date                          object\n",
       "heure                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14616, 15)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 15 columns\n",
      "DataFrame columns: ['ville', 'pays', 'intensite_vent', 'humidite_specifique', 'composante_est_ouest_vent', 'temperature_humide', 'pression', 'temperature_air', 'direction_vent', 'humidite_relative', 'vitesse_vent', 'temperature_point_rosee', 'precipitations_corrigees', 'date', 'heure']\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted final batch of 48 rows\n",
      "Data insertion completed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def insert_postgres_data(dataframe, batch_size=200):\n",
    "     # Connexion à PostgreSQL\n",
    "    conn = psycopg2.connect(dbname=DB_NAME, user=POSTGRES_USER, password=POSTGRES_PASSWORD, host=POSTGRES_HOST)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Créer la table si elle n'existe pas (en respectant le bon ordre)\n",
    "    cur.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            ville VARCHAR(255),\n",
    "            pays VARCHAR(255),\n",
    "            temperature_air FLOAT,\n",
    "            pression FLOAT,\n",
    "            intensite_vent FLOAT,\n",
    "            humidite_specifique FLOAT,\n",
    "            temperature_point_rosee FLOAT,\n",
    "            composante_est_ouest_vent FLOAT,\n",
    "            vitesse_vent FLOAT,\n",
    "            humidite_relative FLOAT,\n",
    "            direction_vent FLOAT,\n",
    "            temperature_humide FLOAT,\n",
    "            precipitations_corrigees FLOAT,\n",
    "            date DATE,\n",
    "            heure VARCHAR(255)\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    \n",
    "    # Vérifier le nombre de colonnes dans le DataFrame\n",
    "    column_count = len(dataframe.columns)\n",
    "    print(f\"DataFrame has {column_count} columns\")\n",
    "    print(f\"DataFrame columns: {dataframe.columns.tolist()}\")\n",
    "    \n",
    "    # Liste des colonnes attendues dans le bon ordre\n",
    "    expected_columns = [\n",
    "        'ville', 'pays', 'temperature_air', 'pression', 'intensite_vent', \n",
    "        'humidite_specifique', 'temperature_point_rosee', 'composante_est_ouest_vent',\n",
    "        'vitesse_vent', 'humidite_relative', 'direction_vent', \n",
    "        'temperature_humide', 'precipitations_corrigees', 'date', 'heure'\n",
    "    ]\n",
    "    \n",
    "    # Ajuster le DataFrame\n",
    "    dataframe = dataframe[expected_columns]\n",
    "        \n",
    "    # Préparer les données pour l'insertion\n",
    "    batch = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        row_tuple = tuple(row.values)\n",
    "        if len(row_tuple) != 15:\n",
    "            print(f\"Warning: Row has {len(row_tuple)} values, expected 15\")\n",
    "            continue\n",
    "        batch.append(row_tuple)\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            try:\n",
    "                query = f\"\"\"\n",
    "                    INSERT INTO {TABLE_NAME} \n",
    "                    (\n",
    "                        ville, pays, temperature_air, pression, intensite_vent, \n",
    "                        humidite_specifique, temperature_point_rosee, composante_est_ouest_vent,\n",
    "                        vitesse_vent, humidite_relative, direction_vent, \n",
    "                        temperature_humide, precipitations_corrigees, date, heure\n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "                cur.executemany(query, batch)\n",
    "                conn.commit()\n",
    "                print(f\"Inserted batch of {len(batch)} rows\")\n",
    "                batch = []\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting batch: {e}\")\n",
    "                if batch:\n",
    "                    print(f\"First row in batch: {batch[0]}\")\n",
    "                conn.rollback()\n",
    "    \n",
    "    # Insérer le dernier batch\n",
    "    if batch:\n",
    "        try:\n",
    "            query = f\"\"\"\n",
    "                INSERT INTO {TABLE_NAME} \n",
    "                (\n",
    "                    ville, pays, temperature_air, pression, intensite_vent, \n",
    "                    humidite_specifique, temperature_point_rosee, composante_est_ouest_vent,\n",
    "                    vitesse_vent, humidite_relative, direction_vent, \n",
    "                    temperature_humide, precipitations_corrigees, date, heure\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.executemany(query, batch)\n",
    "            conn.commit()\n",
    "            print(f\"Inserted final batch of {len(batch)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting final batch: {e}\")\n",
    "            if batch:\n",
    "                print(f\"First row in batch: {batch[0]}\")\n",
    "            conn.rollback()\n",
    "    \n",
    "    print(\"Data insertion completed\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# Exemple d'appel à la fonction\n",
    "insert_postgres_data(df_cleaned, batch_size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'meteo_data' cleared successfully.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "def __clear_cube__():\n",
    "    try:\n",
    "        # Connexion à la base de données cible\n",
    "        with psycopg2.connect(\n",
    "            dbname=\"meteo_db\",\n",
    "            user=\"postgres\",\n",
    "            password=\"passer\",\n",
    "            host=\"localhost\"\n",
    "        ) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Liste des tables à vider\n",
    "                tables_to_clear = [\n",
    "                    \"meteo_data\",\n",
    "\n",
    "                ]\n",
    "                \n",
    "                # Exécuter TRUNCATE sur chaque table\n",
    "                for table in tables_to_clear:\n",
    "                    cur.execute(f\"TRUNCATE TABLE {table} RESTART IDENTITY CASCADE;\")\n",
    "                    print(f\"Table '{table}' cleared successfully.\")\n",
    "                \n",
    "                # Commit des modifications\n",
    "                conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing tables: {e}\")\n",
    "        return False\n",
    "    \n",
    "__clear_cube__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
